{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 1: Install only Gradio & verify existing packages ───────────────────────\n",
        "# Colab already includes numpy, pandas, matplotlib, pillow, and tensorflow,\n",
        "# so we only need to install Gradio.\n",
        "!pip install gradio==3.36.0 --quiet\n",
        "\n",
        "# Verify versions of all key libraries\n",
        "import numpy as np, pandas as pd, matplotlib, PIL, tensorflow as tf, gradio\n",
        "print(f\"▶ numpy      {np.__version__}\")\n",
        "print(f\"▶ pandas     {pd.__version__}\")\n",
        "print(f\"▶ matplotlib {matplotlib.__version__}\")\n",
        "print(f\"▶ Pillow     {PIL.__version__}\")\n",
        "print(f\"▶ tensorflow {tf.__version__}\")\n",
        "print(f\"▶ gradio     {gradio.__version__}\")\n"
      ],
      "metadata": {
        "id": "vLiP2gxSgcRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 2 (UPDATED): Imports, Seeding & Label Names ───────────────────────────\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import gradio as gr\n",
        "import random\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# User-friendly class names for FashionMNIST labels 0–9\n",
        "LABEL_NAMES = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "print(f\"▶ Random seed set to {SEED}\")\n",
        "print(\"▶ Label mapping:\", {i: name for i, name in enumerate(LABEL_NAMES)})\n"
      ],
      "metadata": {
        "id": "KbDZTOg9ahpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 3: Load Data & Quick Inspect ────────────────────────────────────────────\n",
        "# Load the CSV files from Colab's local filesystem\n",
        "train_df = pd.read_csv('fashion-mnist_train.csv')\n",
        "test_df  = pd.read_csv('fashion-mnist_test.csv')"
      ],
      "metadata": {
        "id": "G2La8jREaiFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Print dataset shapes\n",
        "print(f\"▶ train_df.shape = {train_df.shape}\")\n",
        "print(f\"▶ test_df.shape  = {test_df.shape}\")\n"
      ],
      "metadata": {
        "id": "ElaNrTQ1kNXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Peek at column names and first row\n",
        "print(\"▶ train_df columns:\", train_df.columns.tolist())\n",
        "print(\"▶ train_df first row:\\n\", train_df.head(1))"
      ],
      "metadata": {
        "id": "vQX5s8RjkVNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Check for any missing values\n",
        "missing_train = train_df.isnull().sum().sum()\n",
        "print(f\"▶ Missing values in train_df: {missing_train}\")\n",
        "\n",
        "# 4) Label distribution in the training set\n",
        "label_counts = train_df['label'].value_counts().sort_index()\n",
        "print(\"▶ Label distribution:\\n\", label_counts)\n",
        "\n",
        "# 5) Pixel intensity range across all pixels\n",
        "pixel_min = train_df.iloc[:,1:].values.min()\n",
        "pixel_max = train_df.iloc[:,1:].values.max()\n",
        "print(f\"▶ Pixel value range: [{pixel_min}, {pixel_max}]\")\n"
      ],
      "metadata": {
        "id": "cSA_1YAIkJcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Visualize one example image\n",
        "example = train_df.iloc[0]\n",
        "img_arr  = example.values[1:].astype(np.uint8).reshape(28,28)\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(img_arr, cmap='gray')\n",
        "plt.title(f\"Label = {example[0]}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tnw-q_N_kLAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 4: Preprocess & Split ───────────────────────────────────────────────────\n",
        "# Normalize pixel values to [0,1] and separate features/labels\n",
        "X        = train_df.iloc[:,1:].values.astype('float32') / 255.0\n",
        "y        = train_df.iloc[:,0].values.astype('int32')\n",
        "X_test   = test_df.iloc[:,1:].values.astype('float32') / 255.0\n",
        "y_test   = test_df.iloc[:,0].values.astype('int32')\n",
        "\n",
        "# Shuffle the training data\n",
        "perm = np.random.permutation(len(X))\n",
        "X, y = X[perm], y[perm]\n",
        "print(f\"▶ First 5 labels after shuffling: {y[:5]}\")\n",
        "\n",
        "# Split into 90% train / 10% validation\n",
        "split_idx    = int(0.9 * len(X))\n",
        "X_train, y_train = X[:split_idx], y[:split_idx]\n",
        "X_val,   y_val   = X[split_idx:], y[split_idx:]\n",
        "print(f\"▶ Split sizes → train: {len(X_train)}, val: {len(X_val)}, test: {len(X_test)}\")\n",
        "# ─── End of Cell 4 ───────────────────────────────────────────────────────────────\n"
      ],
      "metadata": {
        "id": "gKC886ePajQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 5: Build & Compile TensorFlow Model ────────────────────────────────────\n",
        "# Define a simple feed-forward neural network with one hidden layer\n",
        "\n",
        "\n",
        "# Compile with Adam optimizer and cross-entropy loss\n",
        "\n",
        "# Display the model summary\n",
        "# ─── End of Cell 5 ───────────────────────────────────────────────────────────────\n"
      ],
      "metadata": {
        "id": "irbD2OGqak2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 6: Train & Plot Curves ──────────────────────────────────────────────────\n",
        "# Train for 20 epochs with validation\n"
      ],
      "metadata": {
        "id": "skNOlSODamSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss\n",
        "\n",
        "# Plot training & validation accuracy\n"
      ],
      "metadata": {
        "id": "lOMYHTvRkrOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 7 (UPDATED): Evaluate on Test Set & Visualize Samples ─────────────────\n",
        "# Evaluate final performance on the test set\n"
      ],
      "metadata": {
        "id": "G72mg8uTanyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 8: Save Trained Model with Proper Extension ──────────────────────\n",
        "# TensorFlow requires a file extension; use the native Keras format (.keras)\n",
        "\n",
        "# Save the model\n",
        "\n",
        "# Use: loaded_model = tf.keras.models.load_model(MODEL_PATH) to reload later\n",
        "# ─── End of Updated Cell ────────────────────────────────────────────────────────\n"
      ],
      "metadata": {
        "id": "VaYzuSZyc4EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Cell 9: Load Saved Model for Inference ────────────────────────────────────\n",
        "\n",
        "# Define path to the saved model directory\n",
        "\n",
        "# Load the model\n",
        "\n",
        "# (Optional) Verify by showing its architecture\n",
        "# ─── End of New Cell ─────────────────────────────────────────────────────────────\n"
      ],
      "metadata": {
        "id": "gKm2drzdc6RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize 5 random test images with Predicted vs. Actual labels (using names)\n"
      ],
      "metadata": {
        "id": "VNswk-Eb5JLE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}