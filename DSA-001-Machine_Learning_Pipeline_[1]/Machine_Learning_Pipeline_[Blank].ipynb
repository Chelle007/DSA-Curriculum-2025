{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 1 - Data Ingestion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdcIZ1nrWPoM"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install specific library versions\n",
        "!pip install pandas==1.5.3 \\\n",
        "                numpy==1.24.2 \\\n",
        "                sqlalchemy==2.0.8 \\\n",
        "                scikit-learn==1.2.2 \\\n",
        "                matplotlib==3.7.1 \\\n",
        "                seaborn==0.12.2 \\\n",
        "                gradio==4.44.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZODqcyTWP-2"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Imports & styling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, accuracy_score\n",
        "\n",
        "import gradio as gr\n",
        "import seaborn as sns\n",
        "\n",
        "# Use default matplotlib style for simplicity\n",
        "plt.style.use('default')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Data Ingestion & preview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Missing-value proportions (simple bar chart)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Save data to SQL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 2 - Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Data cleaning via SQL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Views distribution before vs after cleaning (simple histograms)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 3 - Data Exploration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 4 - Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 5 - Model Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 6 - Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 7 - Model Training and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Pipeline 8 - Model Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 16: Gradio Dashboard â€” Title Length EDA & Extended Top Channels\n",
        "def show_dashboard():\n",
        "    # 1) Title length distribution by engagement class\n",
        "    fig1, ax1 = plt.subplots(figsize=(6,3))\n",
        "    ax1.hist(df_feat.loc[df_feat.high_engagement==0, 'TitleLength'],\n",
        "             bins=30, alpha=0.5, label='Low Engagement')\n",
        "    ax1.hist(df_feat.loc[df_feat.high_engagement==1, 'TitleLength'],\n",
        "             bins=30, alpha=0.5, label='High Engagement')\n",
        "    ax1.set_xlabel(\"Title Length (chars)\")\n",
        "    ax1.set_ylabel(\"Count\")\n",
        "    ax1.set_title(\"Title Length by Engagement Class\")\n",
        "    ax1.legend()\n",
        "    fig1.tight_layout()\n",
        "\n",
        "    # 2) Tuned model accuracies\n",
        "    fig2, ax2 = plt.subplots(figsize=(6,3))\n",
        "    names_list = list(tuned_acc.keys())\n",
        "    accs = [tuned_acc[n] for n in names_list]\n",
        "    x = np.arange(len(names_list))\n",
        "    ax2.bar(x, accs, color='lightgreen')\n",
        "    ax2.set_xticks(x)\n",
        "    ax2.set_xticklabels(names_list, rotation=45, ha='right')\n",
        "    ax2.set_ylim(0,1)\n",
        "    ax2.set_ylabel(\"Accuracy\")\n",
        "    ax2.set_title(\"Tuned Model Accuracies\")\n",
        "    fig2.tight_layout()\n",
        "\n",
        "    # 3) Top-10 channels by average predicted engagement\n",
        "    #    using the best RandomForest model\n",
        "    best_model = tuned_models['RandomForest']\n",
        "    probs = best_model.predict_proba(X_test)[:,1]\n",
        "    video_meta = df_feat.loc[X_test.index, ['channel_title']].copy()\n",
        "    video_meta['pred_high_eng'] = probs\n",
        "    channel_probs = video_meta.groupby('channel_title')['pred_high_eng'].mean()\n",
        "    top10_channels = (\n",
        "        channel_probs\n",
        "        .sort_values(ascending=False)\n",
        "        .head(10)\n",
        "        .reset_index()\n",
        "        .rename(columns={'pred_high_eng': 'avg_pred_high_eng'})\n",
        "    )\n",
        "\n",
        "    # 4) Feature importances of the RandomForest\n",
        "    importances = best_model.feature_importances_\n",
        "    imp_df = pd.Series(importances, index=features).sort_values()\n",
        "    fig4, ax4 = plt.subplots(figsize=(6,3))\n",
        "    imp_df.plot.barh(ax=ax4)\n",
        "    ax4.set_title(\"RandomForest Feature Importances\")\n",
        "    fig4.tight_layout()\n",
        "\n",
        "    # Return: title-length hist, accuracies bar, top10 DataFrame, importances\n",
        "    return fig1, fig2, top10_channels, fig4\n",
        "\n",
        "gr.Interface(\n",
        "    fn=show_dashboard,\n",
        "    inputs=[],\n",
        "    outputs=[\n",
        "        gr.Plot(label=\"Title Length by Engagement Class\"),\n",
        "        gr.Plot(label=\"Tuned Model Accuracies\"),\n",
        "        gr.Dataframe(label=\"Top 10 Channels by Predicted Engagement\"),\n",
        "        gr.Plot(label=\"Feature Importances\")\n",
        "    ],\n",
        "    title=\"US YouTube Video Engagement Dashboard & Model Insights\",\n",
        "    description=\"Title length EDA, tuned model performance, top channels, and feature importances.\"\n",
        ").launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
